attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
attach(sample.df)
hist(Price)
hist(log(Price))
lm.res <- lm(log(Price)~H_univ+M_priv+Nurser, data = EV)
summary(lm.res)
#residual map
mapping.seq(sample.shp, lm.res$residuals, nclass=9)
lm.morantest(lm.res, listw=sample.listw)
##Implement MESF
esf.full <- lm(log(Price)~H_univ+M_priv+Nurser+., data = EV)
sample.esf <- stepAIC(lm.res, scope=list(upper= esf.full), direction='forward')
sample.esf <- stepAIC(lm.res, scope=list(upper= esf.full), direction='forward')
summary(sample.esf)
#residual map
mapping.seq(sample.shp, sample.esf$residuals, nclass=9)
lm.morantest(sample.esf, listw=sample.listw)
detach(sample.df)
sample.df
library(NbClust);library(vegan) ##Optimal k selection
library(rgdal)
library(RColorBrewer); library(classInt)
library(ggplot2)
##Read Shapefile
sample.shp <- readOGR(dsn = ".", layer = "Seoul_dong")
sample.df <- data.frame(sample.shp)
xVars <- sample.df[,c("Price", "Year", "Nurser", "Hospit", "Park",
"Culture", "Sub","H_univ", "M_priv","E_prog")]
zXvars <- scale(xVars)
# optimal k for cluster
wss <- c()
for (i in 1:9){
cl <- kmeans(zXvars, centers = i)
wss[i] <- cl$tot.withinss
}
plot(1:9, wss, type="b", xlab="Number of Cluster", ylab="within groups sum of squares")
nb <- NbClust(zXvars, min.nc = 2, max.nc = 10, method = "kmeans")
hist(nb$Best.nc[1,], breaks = 10) ##limited to 10.
model1 <- cascadeKM(zXvars, 1, 10, iter = 15)
plot(model1, sortg = TRUE) # END determin number of K
K <- 3
neighClus <- kmeans(zXvars, centers = K)
##Mapping
pal.Qual <- brewer.pal(12, "Set3")
map.col <- pal.Qual[neighClus$cluster]
qual.Name <- levels(as.factor(neighClus$cluster))
par(mfrow=c(1,1))
plot(sample.shp, col=map.col)
legend("bottomleft", title = "", legend = qual.Name, cex = 1,
fill = pal.Qual[1:length(qual.Name)], bty = "n", ncol = 1)
##Summary clusters
p <- length(xVars)
sum.res <- NULL
cls <- as.factor(1:K)
for(i in 1:p){
var.mean <- neighClus$centers[,i]
tmp.res <- cbind(rep(i, K), var.mean, cls)
sum.res <- rbind(sum.res, tmp.res)
}
sum.res <- data.frame(sum.res)
sum.res$cls <- as.factor(sum.res$cls)
sum.res$color <- 0
sum.res$color[which(sum.res$var.mean>0)] <- 1
ggplot(sum.res, aes(x=V1, y=var.mean, fill=as.factor(color))) +
geom_bar(stat='identity', position='identity', width=0.5)+
facet_grid(cls ~ ., scales='free_y')+
scale_x_discrete(limits=factor(c(1:p)), labels=colnames(xVars))+
labs(y="Average", x="Variables")
# rm(list=ls())
library(car)
library(rgdal)
library(RColorBrewer); library(classInt)
##Mapping function
mapping.seq <- function(polys, x, nclass, main="") {
pal.red <- brewer.pal(nclass, "Reds")
q.n <- classIntervals(x, nclass, style="quantile")
cols.red <- findColours(q.n, pal.red)
plot(polys, col=cols.red)
brks <- round(q.n$brks,2)
leg <- paste(brks[-(nclass+1)], brks[-1], sep=" - ")
legend("bottomright", fill=pal.red, legend=leg, bty="n")
if (!missing(main)) title(main)
}
##Read Shapefile
sample.shp <- readOGR(dsn = ".", layer = "Seoul_dong")
sample.df <- data.frame(sample.shp)
seoul <- sample.df[,c("Price", "Year", "Nurser", "Hospit", "Park",
"Culture", "Sub","H_univ", "M_priv","E_prog")]
plot(sample.shp, col="grey")
mapping.seq(sample.shp, x=seoul$H_univ, nclass=9)
scatterplotMatrix(seoul)
corSeoul <- cor(seoul)            # correlation matrix
print(corSeoul, digits=2)
##
## Principal component analysis on correlation matrix including component scores
##
?princomp # study online help
pcSeoul <- princomp(seoul, cor=TRUE, scores=TRUE)
summary(pcSeoul, loadings=TRUE, cutoff=0.3)
apply(pcSeoul$loadings^2,1,sum)         # row-sum of squared loadings
apply(pcSeoul$loadings^2,2,sum)         # column-sum of squared loadings
round(pcSeoul$sdev^2, 2)                # eigenvalues = variance explained by component
round(pcSeoul$sdev^2, 2)/sum(pcSeoul$sdev^2)
pcLoad <- pcSeoul$loadings %*% diag(pcSeoul$sdev) # loadings (colums scaled by eigenvalue)
print(pcLoad, digits=2)
apply(pcLoad^2,2,sum)                             # squared loadings of factors = variance explained
## Component scores
( pcScores <- pcSeoul$scores )            # observation value associated with each component
print(round(cor(pcScores), 2))            # uncorrelated component scores
round(apply(pcScores,2,var) * 422/423, 2) # Each component has the eigenvalue as variance
( pcLoad2 <- cor(seoul,pcScores[,1:2]) ) # see loading of first two components
## Descriptive plots
screeplot(pcSeoul, type="lines")        # Scree graph
abline(h=1,lty=2)
biplot(pcSeoul)                         # unrotated components
abline(h=0,v=0, lty=5)
## Descriptive plots
screeplot(pcSeoul, type="lines")        # Scree graph
abline(h=1,lty=2)
biplot(pcSeoul)                         # unrotated components
abline(h=0,v=0, lty=5)
##
## Principle component analysis using matrix expressions
##
zSeoul <- scale(seoul)
zSeoul
round(mean(zSeoul[,1]), 5)
scatterplotMatrix(zSeoul)
( corSeoul <- t(zSeoul) %*% zSeoul /423)
eigSys <- eigen(corSeoul, symmetric=TRUE)   # eigen-system decomposition of correlation matrix
eigVal <- eigSys$values                     # eigenvalues
eigVec <- eigSys$vectors                    # eigenvectors equivalent with rotation matrix A
pcScores <- zSeoul %*% eigVec               # Component scores
( pcLoad <- cor(zSeoul,pcScores[,1:2]) )
cat("Eigenvalues:\n");eigVal
cat("Percent Explained Variance:\n");cumsum(eigVal)/sum(eigVal)
cat("Rotation A:\n");eigVec
cat("Component Scores:\n");round(pcScores,3)
cat("Componet Loadings:\n");pcLoad
pcLoad
# View(teens)
##
## Exploring and cleaning the data
## Problem: To many records will be lost if on drops records with just one NA
##
table(teens$gender)                       # look at missing gender data
teens <- read.csv("snsdata.csv")
# View(teens)
##
## Exploring and cleaning the data
## Problem: To many records will be lost if on drops records with just one NA
##
table(teens$gender)                       # look at missing gender data
table(teens$gender, useNA = "ifany")
summary(teens$age)                        # look at missing data for age variable
## eliminate age outliers
teens$age <- ifelse(teens$age >= 13 & teens$age < 20,
teens$age, NA)
summary(teens$age)
## reassign missing gender values to "unknown"
teens$female <- ifelse(teens$gender == "F" &
!is.na(teens$gender), 1, 0)
teens$no_gender <- ifelse(is.na(teens$gender), 1, 0)
teens$no_gender <- factor(teens$no_gender, levels=c(0,1), labels=c("response","no response"))
table(teens$gender, useNA = "ifany")      # check the recoding work
table(teens$female, useNA = "ifany")
table(teens$no_gender, useNA = "ifany")
## finding the mean age by cohort
mean(teens$age)               # doesn't work
mean(teens$age, na.rm = TRUE) # works
aggregate(data = teens, age ~ gradyear, mean, na.rm = TRUE)  # age by cohort
## create a vector with the average age for each gradyear, repeated by person
ave_age <- ave(teens$age, teens$gradyear,
FUN = function(x) mean(x, na.rm = TRUE))
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
## check the summary results to ensure missing values are eliminated
summary(teens$age)
## recode expected graduation year
teens$grade <- factor(teens$gradyear, levels=c(2006,2007,2008,2009),
labels=c("senior","junior","sophomore","freshman"))
## create a z-score standardized data frame for easier interpretation
interests <- teens[5:40]
summary(interests)            # word frequencies highly positively skewed
interestsZ <- as.data.frame(lapply(interests, scale))
summary(interestsZ)
## create the clusters using k-means
set.seed(2345)
teenClusters <- kmeans(interestsZ, 5)
##
## Evaluate model performance: intra cluster homogeneity and between cluster heterogeneity
##
teenClusters$size                     # look at the size of the clusters
teenClusters$totss
teenClusters$withinss
teenClusters$tot.withinss
teenClusters$betweenss
##
## Evaluate meaning of clusters by their feature means
## Investigate above and below average responses (value zero) by group
##
round(teenClusters$centers, 1)        # look at the cluster centers
clustCent <- teenClusters$centers
clustCent[clustCent > -0.1 & clustCent < 0.4] <- NA
round(t(clustCent), 1)
##
##  Attributes of respondents by cluster membership
##
teens$cluster <- teenClusters$cluster                # label records by cluster IDs
mean(teens$age)
aggregate(data = teens, age ~ cluster, mean)         # mean age by cluster
mean(teens$female)
aggregate(data = teens, female ~ cluster, mean)      # proportion of females by cluster
mean(teens$friends)
aggregate(data = teens, friends ~ cluster, mean)     # mean number of friends by cluster
##Load data
sample.shp <- readShapePoly("Seoul_dong.shp")
sample.df <- as.data.frame(sample.shp)
plot(sample.shp, col="grey")
# rm(list=ls(all=TRUE))
library(spdep); library(maptools)
library(MASS)
library(RColorBrewer); library(classInt)
# setwd("D:\\Google Drive\\UOS\\2021\\2학기\\머신러닝\\3\\Data")
# setwd("E:/04. TalentPlatform/Github/TalentPlatform-R/src/subject/LSH0232")
##Mapping function
mapping.seq <- function(polys, x, nclass, main="") {
pal.red <- brewer.pal(nclass, "Reds")
q.n <- classIntervals(x, nclass, style="quantile")
cols.red <- findColours(q.n, pal.red)
plot(polys, col=cols.red)
brks <- round(q.n$brks,2)
leg <- paste(brks[-(nclass+1)], brks[-1], sep=" - ")
legend("bottomright", fill=pal.red, legend=leg, bty="n")
if (!missing(main)) title(main)
}
##Load data
sample.shp <- readShapePoly("Seoul_dong.shp")
sample.df <- as.data.frame(sample.shp)
plot(sample.shp, col="grey")
##Create spatial weights matrix
sample.nb <- poly2nb(sample.shp, queen = T)
sample.n <- length(sample.nb)
sample.nb
sample.n <- length(sample.nb)
sample.n
sample.listw
# 공간 가중 행렬 생성
sample.listw <- nb2listw(sample.nb, style='W')
sample.listb <- nb2listw(sample.nb, style='B')
sample.listb
##Generate MBM
B <- listw2mat(sample.listb)
M <- diag(sample.n) - matrix(1/sample.n, sample.n, sample.n)
MBM <- M%*%B%*%M
##Extract Eigenvectors and eigenvalues
eig <- eigen(MBM)
plot(1:423, eig$values)
round(cor(eig$vectors[,99], eig$vectors[,3]), 6)
# 제2성분 지도 결과
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "제2주성분의 성분점수")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,2], nclass=9)
moran.test(eig$vectors[,2], sample.listb, randomisation=TRUE)
dev.off()
##Relationship between eigenvalues and Moran's I
mc.res <- vector('numeric', sample.n)
for(i in 1:sample.n){
mc.res[i] <- moran.test(eig$vectors[,i], sample.listb, randomisation=TRUE)$estimate[1]
}
plot(eig$values, mc.res)
##
##Drawing EV maps with W matrix
##
W <- listw2mat(sample.listw)
sum(apply(W, 1, sum))
MWM <- M%*%W%*%M
eig <- eigen(MWM)
W
##Drawing eigenvector maps
mapping.seq(sample.shp, x=eig$vectors[,1], nclass=9)
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
##Drawing eigenvector maps
mapping.seq(sample.shp, x=eig$vectors[,1], nclass=9)
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
##Drawing eigenvector maps
mapping.seq(sample.shp, x=eig$vectors[,1], nclass=9)
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
mapping.seq(sample.shp, x=eig$vectors[,423], nclass=9)
moran.test(eig$vectors[,423], sample.listw, randomisation=TRUE)
##Drawing eigenvector maps
mapping.seq(sample.shp, x=eig$vectors[,1], nclass=9)
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
moran.test(eig$vectors[,423], sample.listw, randomisation=TRUE)
##Drawing eigenvector maps
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "강한 양의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,1], nclass=9)
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
dev.off()
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "낮은 음음의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,423], nclass=9)
moran.test(eig$vectors[,423], sample.listw, randomisation=TRUE)
dev.off()
# 낮은 음의 공간적 자기상관
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "낮은 음의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,423], nclass=9)
moran.test(eig$vectors[,423], sample.listw, randomisation=TRUE)
dev.off()
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
# 역거리 기반 공간가중행렬
D <- sp::spDists(sample.shp)/1000
D <- 1/D
diag(D)<-0
D <- sp::spDists(sample.shp)/1000
D <- 1/D
diag(D)<-0
MBM <- M%*%D%*%M
eig <- eigen(MWM)
eig
##Drawing eigenvector maps
# 강한 양의 공간적 자기상관
# saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "강한 양의 공간적 자기상관")
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "역거리-강한 양의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,1], nclass=9)
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
dev.off()
# 낮은 음의 공간적 자기상관
# saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "낮은 음의 공간적 자기상관")
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "역거리-낮은 음의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,423], nclass=9)
moran.test(eig$vectors[,423], sample.listw, randomisation=TRUE)
dev.off()
# 역거리 기반 공간가중행렬
D <- sp::spDists(sample.shp)/1000
D <- 1/D
diag(D)<-0
MBM <- M%*%D%*%M
eig <- eigen(MWM)
eig
# 역거리 기반 공간가중행렬
D <- sp::spDists(sample.shp)/1000
D <- 1/D
sample.shp
# 역거리 기반 공간가중행렬
D <- sp::spDists(sample.shp)/1000
D <- 1/D
diag(D)<-0
diag(D)
D
MBM <- M%*%D%*%M
eig <- eigen(MWM)
eig
##Drawing eigenvector maps
# 강한 양의 공간적 자기상관
# saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "강한 양의 공간적 자기상관")
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "역거리-강한 양의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,1], nclass=9)
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
dev.off()
# 낮은 음의 공간적 자기상관
# saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "낮은 음의 공간적 자기상관")
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "역거리-낮은 음의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,423], nclass=9)
moran.test(eig$vectors[,423], sample.listw, randomisation=TRUE)
dev.off()
##Relationship between eigenvalues and Moran's I
mc.res <- vector('numeric', sample.n)
for(i in 1:sample.n){
mc.res[i] <- moran.test(eig$vectors[,i], sample.listw, randomisation=TRUE)$estimate[1]
}
plot(eig$values, mc.res)
##
## Moran eigenvector spatial filtering
##
eig <- eigen(MBM)
EV <- as.data.frame( eig$vectors[,]); colnames(EV) <- paste('EV', 1:NCOL(EV), sep='')
##Select Candiate EVs
np <- length(eig$values[eig$values/eig$values[1]>0.20])
EV <- EV[,1:np]
##Linear regression
attach(sample.df)
hist(Price)
hist(log(Price))
lm.res <- lm(log(Price)~H_univ+M_priv+Nurser, data = EV)
summary(lm.res)
#residual map
mapping.seq(sample.shp, lm.res$residuals, nclass=9)
lm.morantest(lm.res, listw=sample.listw)
##Implement MESF
esf.full <- lm(log(Price)~H_univ+M_priv+Nurser+., data = EV)
sample.esf <- stepAIC(lm.res, scope=list(upper= esf.full), direction='forward')
summary(sample.esf)
#residual map
mapping.seq(sample.shp, sample.esf$residuals, nclass=9)
lm.morantest(sample.esf, listw=sample.listw)
detach(sample.df)
sample.esf <- stepAIC(lm.res, scope=list(upper= esf.full), direction='forward')
summary(sample.esf)
W <- listw2mat(sample.listw)
sum(apply(W, 1, sum))
sum(apply(W, 1, sum))
sum(apply(W, 1, sum))
MWM <- M%*%W%*%M
MWM
summary(MWM)
# 역거리 기반 공간가중행렬
D <- sp::spDists(sample.shp)/1000
D <- 1/D
diag(D)<-0
MBM <- M%*%D%*%M
##
##Drawing EV maps with W matrix
##
# 연접성 기반 이항 공간가중행렬
W <- listw2mat(sample.listw)
sum(apply(W, 1, sum))
MWM <- M%*%W%*%M
eig <- eigen(MWM)
eig <- eigen(MBM)
##Drawing eigenvector maps
# 강한 양의 공간적 자기상관
# saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "강한 양의 공간적 자기상관")
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "역거리-강한 양의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,1], nclass=9)
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
dev.off()
# 낮은 음의 공간적 자기상관
# saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "낮은 음의 공간적 자기상관")
saveImg = sprintf("%s/%s_%s.png", ".", "LSH0232", "역거리-낮은 음의 공간적 자기상관")
png(file = saveImg, width = 10, height = 8, units = "in", res = 600)
mapping.seq(sample.shp, x=eig$vectors[,423], nclass=9)
moran.test(eig$vectors[,423], sample.listw, randomisation=TRUE)
dev.off()
moran.test(eig$vectors[,1], sample.listw, randomisation=TRUE)
moran.test(eig$vectors[,423], sample.listw, randomisation=TRUE)
library(NbClust);library(vegan) ##Optimal k selection
library(rgdal)
library(RColorBrewer); library(classInt)
library(ggplot2)
##Read Shapefile
sample.shp <- readOGR(dsn = ".", layer = "Seoul_dong")
sample.df <- data.frame(sample.shp)
xVars <- sample.df[,c("Price", "Year", "Nurser", "Hospit", "Park",
"Culture", "Sub","H_univ", "M_priv","E_prog")]
zXvars <- scale(xVars)
# optimal k for cluster
wss <- c()
for (i in 1:9){
cl <- kmeans(zXvars, centers = i)
wss[i] <- cl$tot.withinss
}
plot(1:9, wss, type="b", xlab="Number of Cluster", ylab="within groups sum of squares")
nb <- NbClust(zXvars, min.nc = 2, max.nc = 10, method = "kmeans")
hist(nb$Best.nc[1,], breaks = 10) ##limited to 10.
model1 <- cascadeKM(zXvars, 1, 10, iter = 15)
model1
plot(model1, sortg = TRUE) # END determin number of K
K <- 3
neighClus <- kmeans(zXvars, centers = K)
neighClus
##Mapping
pal.Qual <- brewer.pal(12, "Set3")
map.col <- pal.Qual[neighClus$cluster]
qual.Name <- levels(as.factor(neighClus$cluster))
par(mfrow=c(1,1))
plot(sample.shp, col=map.col)
legend("bottomleft", title = "", legend = qual.Name, cex = 1,
fill = pal.Qual[1:length(qual.Name)], bty = "n", ncol = 1)
##Summary clusters
p <- length(xVars)
sum.res <- NULL
cls <- as.factor(1:K)
for(i in 1:p){
var.mean <- neighClus$centers[,i]
tmp.res <- cbind(rep(i, K), var.mean, cls)
sum.res <- rbind(sum.res, tmp.res)
}
sum.res <- data.frame(sum.res)
sum.res$cls <- as.factor(sum.res$cls)
sum.res$color <- 0
sum.res$color[which(sum.res$var.mean>0)] <- 1
ggplot(sum.res, aes(x=V1, y=var.mean, fill=as.factor(color))) +
geom_bar(stat='identity', position='identity', width=0.5)+
facet_grid(cls ~ ., scales='free_y')+
scale_x_discrete(limits=factor(c(1:p)), labels=colnames(xVars))+
labs(y="Average", x="Variables")
