---
title: "Assignment 8: CP2"
author: "Sangwon Yum"
date: "`r Sys.Date()`"
documentclass: article
geometry: margin=1in
fontsize: 11pt
output:
  pdf_document:
    highlight: tango
    toc: false
    df_print: kable
    fig_caption: no
    number_sections: no
    dev: pdf
    latex_engine: xelatex
# mainfont: "Malgun Gothic"
---

```{r setup, include = FALSE}
# DO NOT ALTER THIS CHUNK
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  fig.width = 5,
  fig.asp = 0.618,
  out.width = "70%",
  dpi = 120,
  fig.align = "center",
  cache = FALSE
)

# Cost function for cross validation
cost <- function(obs, pred) {
  outcome <- pred > 0.5
  return(1 - (sum(obs == outcome) / length(obs)))
}

# Load required packages
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggmosaic))
suppressPackageStartupMessages(library(modelr))
suppressPackageStartupMessages(library(boot))
```

## Exercise 1
```{r}
train_df = read_csv(file = "train.csv") %>% 
  dplyr::mutate(
    across(c(Pclass, SibSp, Parch), as.character)
    , did_survive = as.logical(Survived)
    )


test_df = read_csv(file = "test.csv")
```



## Exercise 2
- Q) How do the Age and Fare distributions differ for survivors versus passengers who died?
- A) Age에서 생존자의 경우 저연령 (0 ~ 10세)에서 높은 생존율을 보이며 이는 타이타닉호 침몰 당시에 어린이/여성을 우선순위로 구조되었던 역사실 사실과 일치함. 반면에 사망자의 경우 넓은 연령대로 분포하나 특히 중년대가 많은 빈도를 차지함
- A) Fare에서 생존자의 경우 상급석 (요금 높은 클래스) 승객은 더 높은 생존율을 나타내나 사망자에서는 이와 정반대로 하급석 (요금 낮은 클래스)에서 높은 사망율을 보임

- Q) Do you think the differences in the distributions of these variables will be helpful predictors of survival?
- A) 앞서 설명한 바와 같이 Age, Fare에서 생존자/사망자에 대한 정보를 내포하고 있기 때문에 유용한 예측 변수로 판단됨
```{r}
train_df %>% 
  tidyr::pivot_longer(cols = c(Age, Fare), names_to = "key", values_to = "val") %>% 
  ggplot() +
    geom_histogram(
      mapping = aes(x = val, fill = did_survive)
      , position = "identity", alpha = 0.5
    ) +
    facet_wrap(~ key, scales = "free") +
    labs(title = "Histograms of Age and Fare by Survival", x = "Value", y = "Frequency", fill = "Survived")
```



## Exercise 3
- Q) Which of these variables are good predictors for survival?
- A) Sex, Pclass

- Q) Which of these variables are poor predictors of survival?
- A) Parch, SibSp

- Q) Do these results make sense considering the circumstances of how people were prioritized for boarding lifeboats?
- A) Sex

- Q) Which predictor do you think was the most useful for predicting survival?
- A) Sex, Pclass
```{r}
train_df %>% 
  tidyr::pivot_longer(cols = c(Pclass, Sex, Parch, SibSp), names_to = "key", values_to = "val") %>% 
  ggplot(mapping = aes(x = val, fill = did_survive, label = ..count..)) +
    geom_bar(position = "dodge") +
    facet_wrap(~ key, scales = "free") +
    labs(title = "Bar Plots of Pclass, Sex, Parch, and SibSp by Survival", x = "Category", y = "Count", fill = "Survived")
```



## Exercise 4
- Q) How does the interaction of gender and passenger class seem to affect survival?
- A) 남성보다 여성의 생존율 높음, 3등석보다 상급석 (1등석, 2등석)의 생존율 높음. 따라서 성별과 승객 등급이 생존에 중요한 영향을 끼침

- Q) Is there a difference in survival for each class based on gender?
- A) 여성의 경우 승객 등급과 관계없이 남성보다 높은 생존율을 보임. 특히 상급석 (1등석, 2등석)은 3등석보다 더 높은 생존율을 나타냄.
- A) 남성의 경우  상급석 (1등석, 2등석)은 3등석보다 더 높은 생존율을 나타내고 특히 3등석에서 가장 낮은 생존율을 보임
```{r}
train_df %>% 
  ggplot() +
    geom_mosaic(mapping = aes(x = product(Sex, Pclass), fill = Sex)) +
    facet_grid(. ~ did_survive, scales = "free") +
    labs(title = "Mosaic plot of who wurvived the Titanic", x = "Passenger class", y = "Gender")
```



## Exercise 5
```{r}
train_df %>% 
  dplyr::summarise(
    total = n()
    , missing = sum(is.na(Age))
    , fraction_missing = missing / total
  )

train_imputed = train_df %>% 
  dplyr::mutate(
    age_imputed = if_else(
      condition = is.na(Age)
      , true = median(Age, na.rm = TRUE)
      , false = Age
    )
  )

train_imputed %>%
  dplyr::summarise(
    total = n()
    , missing = sum(is.na(age_imputed))
    , fraction_missing = missing / total
  )
```



## Exercise 6
- Q) What is the accuracy of your model?
- A) moderate (0.62)
```{r}
model_1 = glm(Survived ~ age_imputed, family = "binomial", data = train_imputed)
model_1

model_1_preds = train_imputed %>% 
  modelr::add_predictions(model_1, type = "response") %>% 
  dplyr::mutate(
    outcome = if_else(pred > 0.5, 1, 0)
    )
model_1_preds

model_1_preds %>% 
  dplyr::mutate(correct = if_else(Survived == outcome, 1, 0)) %>%
  dplyr::summarise(
    total_correct = sum(correct, na.rm = TRUE)
    , accuracy = total_correct / n()
    )
```



## Exercise 7
```{r}
cost = function(y, yhat) {
  prd = ifelse(yhat > 0.5, 1, 0)
  accuracy = mean(y == prd)
  1 - accuracy
}

logistic_cv1 = cv.glm(data = train_imputed, glmfit = model_1, cost = cost, K = 5)
error_model = logistic_cv1$delta[1]
error_model
```



## Exercise 8
- Q) Which of your three models has the most accurate validation error? Why?
- A)
```{r}
model_2 = glm(Survived ~ age_imputed +  SibSp + Pclass + Sex, family = "binomial", data = train_imputed)
cv_model_2 = cv.glm(data = train_imputed, glmfit = model_2, cost = cost, K = 5)
error_model_2 = cv_model_2$delta[1]
error_model_2

model_3 = glm(Survived ~ (age_imputed + SibSp + Pclass + Sex)^2, family = "binomial", data = train_imputed)
cv_model_3 = cv.glm(data = train_imputed, glmfit = model_3, cost = cost, K = 5)
error_model_3 = cv_model_3$delta[1]
error_model_3
```



## Bonus Exercise
If you choose to do the bonus exercise, write your code here. Otherwise you can delete this section.
```{r}

```
