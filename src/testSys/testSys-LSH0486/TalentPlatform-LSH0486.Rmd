---
title: "Lab 7: Birth Ratios"
author: "Sangwon Yum"
date: "`r Sys.Date()`"
documentclass: article
geometry: margin=1in
fontsize: 11pt
output:
  pdf_document:
    highlight: tango
    toc: false
    df_print: kable
    fig_caption: no
    number_sections: no
    dev: pdf
    latex_engine: xelatex
  html_document:
    highlight: tango
    self_contained: true
    theme: paper
    toc: no
    df_print: kable
    fig_caption: no
    number_sections: no
    smart: yes
    dev: svg
  github_document:
    html_preview: false
    pandoc_args: --webtex
    toc: true
    toc_depth: 4
    dev: svg
    df_print: kable
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE, eval = TRUE, fig.width = 6, warning = FALSE,
  message = FALSE,
  fig.asp = 0.618, out.width = "80%", dpi = 120,
  fig.align = "center", cache = FALSE
)

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(modelr))
suppressPackageStartupMessages(library(broom))
suppressPackageStartupMessages(library(HistData))
suppressPackageStartupMessages(library(infer))
```

### Exercise 1
```{r, warning=FALSE}
data = Arbuthnot %>% 
  tibble::tibble()

help(data)
# View(data)


dupData = data %>%
  group_by(Year) %>%
  count() %>%
  filter(n > 1)

print(dupData)
``` 
  
### Exercise 2
```{r, warning=FALSE}
ggplot(data = data) +
  geom_boxplot(aes(x = "", y = Ratio)) +
  coord_flip() +
  labs(title = "Boxplot", x = "Ratio", y = "Value")

ggplot(data = data, aes(x = Ratio)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.01) +
  labs(title = "PMF", x = "Ratio", y = "Probability")
```

### Exercise 3
```{r, warning=FALSE}
ggplot(data = data) +
  geom_density(aes(x = Ratio, y = ..density..), alpha=0.5) +
  geom_histogram(aes(x = Ratio, y = ..density..), binwidth = 0.01, alpha=0.5) +
  labs(title="Density Plot and PMF on the Same Graph", x="Value", y="Density/Probability")
```

### Exercise 4
- Q) Which summary statistics are sensitive to outliers?
- A) mean, sd, min, max

- Q) Which summary statistics are not sensitive to outliers?
- A) median, iqr
```{r, warning=FALSE}
data %>% 
  summarise(
    mean = mean(Ratio, na.rm = TRUE)
    , median = median(Ratio, na.rm = TRUE)
    , sd = sd(Ratio, na.rm = TRUE)
    , iqr = IQR(Ratio, na.rm = TRUE)
    , min = min(Ratio, na.rm = TRUE)
    , max = max(Ratio, na.rm = TRUE)
  )
```

### Exercise 5
- Q) After performing the two-sided hypothesis test, explain the result of your hypothesis testing
- A) 유의수준 (p-value)은 0.05보다 작기 때문에 귀무가설을 기각하고 대립가설을 수행함
     이는 실제 평균 1과 유의미하게 다름
```{r, warning=FALSE}
# Exercise 5 part 1
data_null = data %>% 
  specify(formula = Ratio ~ NULL) %>% 
  hypothesise(null = "point", mu = 1) %>% 
  generate(reps = 10000, type = "bootstrap") %>% 
  calculate(stat = "mean")
print(data_null)

# Exercise 5 part 2
data_obs_stat = data %>% 
  specify(formula = Ratio ~ NULL) %>% 
  calculate(stat = "mean")
print(data_obs_stat)

# Exercise 5 part 3
data_null %>% 
  get_p_value(obs_stat = data_obs_stat, direction = "two-sided")

# Exercise 5 part 4
data_null %>% 
  visualize() +
  shade_p_value(obs_stat = data_obs_stat, direction = "two-sided")
```


### Exercise 6
- Q) Is there a difference between this hypothesis test result and the result of Ex 5?
- A) 앞선 Exercise 5와 동일한 결과임

- Q) Explain why
- A) 두 경우 모두에서 귀무 가설이 기각되었으나 일반적인 시나리오에서는 mu 값의 변경이 결과에 큰 차이를 가져옴
     즉 mu가 샘플 평균과 더 멀리 있을수록 샘플 평균이 그 값에서 통계적으로 유의하게 발생될 확률이 높아짐
```{r, warning=FALSE}
# Exercise 6 part 1
data_null2 = data %>% 
  specify(formula = Ratio ~ NULL) %>% 
  hypothesise(null = "point", mu = 1.05) %>% 
  generate(reps = 10000, type = "bootstrap") %>% 
  calculate(stat = "mean")
print(data_null2)

# Exercise 6 part 2
# Exercise 5 part 2와 동일

# Exercise 6 part 3
data_null2 %>% 
  get_p_value(obs_stat = data_obs_stat, direction = "two-sided")

# Exercise 6 part 4
data_null2 %>%
  visualize() +
  shade_p_value(obs_stat = data_obs_stat, direction = "two-sided")
```